{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 探索数据\n",
    "\n",
    "\n",
    "数据集使用 kaggle 数据集，解压后存放在images目录下\n",
    "- 训练数据集路径：\n",
    "images/train\n",
    "- 测试数据集路径：\n",
    "images/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 整理数据集\n",
    " \n",
    "这里由于 trian 文件夹下的猫和狗的数据是混在一起的，需要将猫和狗的图片分别存储。\n",
    "\n",
    "图片的命名规则：类别.编码.jpg\n",
    "\n",
    "**注意：这里的处理只需要运行一次即可**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.stats import mode as spmode\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "import platform\n",
    "\n",
    "print(platform.system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# windows分隔符\n",
    "splitflag = \"\\\\\"\n",
    "if (platform.system() == 'Linux'):\n",
    "    splitflag = \"/\"\n",
    "\n",
    "#处理的样本量\n",
    "train_limitcount = 10\n",
    "test_limitcount = 100 #不限制个数全部使用\n",
    "\n",
    "def create_dir(path):\n",
    "    '''\n",
    "    创建文件夹\n",
    "    '''\n",
    "    if (os.path.exists(path) == False):\n",
    "        os.mkdir (path)\n",
    "    else:\n",
    "        print('文件夹已经存在：%s' % path)\n",
    "\n",
    "# 限制训练文件数量,0不限制\n",
    "def copy_image_bytype(srcpath, destpath, limitcount = 0):\n",
    "    '''\n",
    "    将猫狗文件分别拷贝到不同文件夹下\n",
    "    '''\n",
    "    \n",
    "    filenames = [item.split(splitflag)[-1] for item in sorted(srcpath)]\n",
    "    \n",
    "    count = 0\n",
    "    for src,name in zip(srcpath,filenames):\n",
    "        dst = destpath + \"/\" + name\n",
    "        if (os.path.exists(dst) == False):\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        # 跳出循环\n",
    "        if (limitcount == count):\n",
    "            break\n",
    "            \n",
    "    return count\n",
    "\n",
    "def file_move(srcpath, despath):\n",
    "    filenames = [item.split(splitflag)[-1] for item in sorted(srcpath)]\n",
    "    count = len(filenames)\n",
    "        \n",
    "    for src,name in zip(srcpath,filenames):\n",
    "        dst = despath + \"/\" + name\n",
    "        if (os.path.exists(src) == True):\n",
    "            shutil.move(src, dst)\n",
    "            \n",
    "    return count\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹已经存在：images/notmatchs\n"
     ]
    }
   ],
   "source": [
    "# 创建文件夹\n",
    "notmatch_path='images/notmatchs'\n",
    "all_path = 'images/all'\n",
    "train_path = 'images/all/trainnew'\n",
    "dog_path = 'images/all/trainnew/dogs'\n",
    "\n",
    "\n",
    "testnew_path = 'images/all/testnew'\n",
    "test_path = 'images/all/testnew/test'\n",
    "\n",
    "shutil.rmtree(all_path)\n",
    "create_dir(notmatch_path)\n",
    "create_dir(all_path)\n",
    "\n",
    "create_dir(train_path)\n",
    "create_dir(dog_path)\n",
    "\n",
    "\n",
    "create_dir(testnew_path)\n",
    "create_dir(test_path)\n",
    "\n",
    "\n",
    "cat_path = 'images/all/trainnew/cats'\n",
    "create_dir(cat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 total dog categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理狗\n",
    "dogs_all = glob(\"images/train/dog.*\")\n",
    "\n",
    "# 整理狗数据\n",
    "count = copy_image_bytype(dogs_all, dog_path, train_limitcount)\n",
    "\n",
    "print('There are %d total dog categories.' % count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 total cat categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理猫\n",
    "cats_all = glob(\"images/train/cat.*\")\n",
    "\n",
    "# 整理猫数据\n",
    "count = copy_image_bytype(cats_all, cat_path, train_limitcount)\n",
    "\n",
    "print('There are %d total cat categories.' % count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 total test categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理测试数据\n",
    "test_all = glob(\"images/test/*\")\n",
    "\n",
    "# 整理猫数据\n",
    "count = copy_image_bytype(test_all, test_path, test_limitcount)\n",
    "\n",
    "print('There are %d total test categories.' % count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "100\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#当前使用的样例\n",
    "dogs_list = glob(dog_path+'/dog.*')\n",
    "print(len(dogs_list))\n",
    "\n",
    "test_list = glob(test_path+'/*')\n",
    "print(len(test_list))\n",
    "\n",
    "cats_list = glob(cat_path+'/cat.*')\n",
    "print(len(cats_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_filesizes(paths):\n",
    "    '''\n",
    "    获取文件大小\n",
    "    '''\n",
    "    filesizes = []\n",
    "    for path in paths:\n",
    "        size = os.path.getsize(path)\n",
    "        filesizes.append(size)\n",
    "    return filesizes\n",
    "\n",
    "def get_filepixs(paths):\n",
    "    '''\n",
    "    获取像素：长和宽\n",
    "    '''\n",
    "    filepixs = []\n",
    "    xpixs = []\n",
    "    ypixs = []\n",
    "    for path in paths:\n",
    "        img = Image.open(path)\n",
    "        pix = img.size #图片的长和宽\n",
    "        xpixs.append(pix[0]) #图片的宽\n",
    "        ypixs.append(pix[1]) #图片的长\n",
    "        if (pix[0] > 1000):\n",
    "            print(path)\n",
    "    filepixs.append(xpixs)\n",
    "    filepixs.append(ypixs)    \n",
    "    \n",
    "    return filepixs\n",
    "    \n",
    "def draw_hist(mylist, title, xlabel, ylabel, xmin, xmax, ymin, ymax):\n",
    "    '''\n",
    "    绘制直方图，参数依次为list,抬头,X轴标签,Y轴标签,XY轴的范围\n",
    "    '''\n",
    "    plt.hist(mylist, 100)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def draw_scatter(x1, y1, title, label):\n",
    "    '''\n",
    "    绘制像素的散点图\n",
    "    '''\n",
    "    plt.scatter(x1, y1, marker = 'x',color = 'red', s = 40 ,label = label)\n",
    "    plt.xlabel('wide')\n",
    "    plt.ylabel('length')\n",
    "    plt.title(title)\n",
    "    \n",
    "#     plt.xlim(-1.5, 1.5)\n",
    "#     plt.xticks(())  # ignore xticks\n",
    "#     plt.ylim(-1.5, 1.5)\n",
    "#     plt.yticks(())  # ignore yticks\n",
    "\n",
    "    plt.show()   \n",
    "\n",
    "    \n",
    "def show_filesize(paths):\n",
    "    '''\n",
    "    展示文件大小分布\n",
    "    '''\n",
    "    filesizes = get_filesizes(paths)\n",
    "\n",
    "    # train 中文件的的最小值、最大值、中位数、众数\n",
    "    train_min = np.min(filesizes)\n",
    "    print('train 中文件的的最小值:', train_min)\n",
    "    train_max = np.max(filesizes)\n",
    "    print('train 中文件的的最大值:', train_max)\n",
    "    train_median = np.median(filesizes)\n",
    "    print('train 中文件的的中位数:', train_median)\n",
    "    train_mode = spmode(filesizes)\n",
    "    print('train 中文件的的众数:', train_mode)\n",
    "        \n",
    "    title = 'file size distribute'\n",
    "    xlabel = 'file size'\n",
    "    ylabel = 'file count'\n",
    "    xmin = np.min(filesizes)\n",
    "    xmax = np.max(filesizes)\n",
    "    ymin = 0\n",
    "    ymax = 1200\n",
    "    draw_hist(filesizes, title, xlabel, ylabel, xmin, xmax, ymin, ymax)\n",
    "\n",
    "def show_filepix(paths):\n",
    "    '''\n",
    "    显示像素分布\n",
    "    '''\n",
    "    filepixs = get_filepixs(paths)\n",
    "    title = 'file pix distribute'\n",
    "    draw_scatter(filepixs[0], filepixs[1], title, 'dog')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f89bbc71d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 狗的数据集图片大小分布\n",
    "\n",
    "show_filepix(dogs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMiAkSb3+P/81uO/KTpIQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f89bbc18550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 猫的数据集图片大小分布\n",
    "show_filepix(cats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练数据集文件大小的分布\n",
    "# show_filesize(dogs_list)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 测试数据集文件大小的分布\n",
    "# show_filesize(cats_list)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 异常数据清理\n",
    "\n",
    "异常数据有:\n",
    "\n",
    "标签与图片信息不相符的，例如：虽然标识了是狗的图片，但是图片中没有狗。\n",
    "\n",
    "照片的背景过于复杂，识别起来很困难，例如：虽然有狗但是有很多干扰元素。\n",
    "\n",
    "这里选择4种算法:ResNet50, VGG19, Xception, InceptionV3 获取的并集进行数据清理\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "#可能概率前几个类型\n",
    "topparma = 50\n",
    "# 筛选的数量\n",
    "doglimit = train_limitcount\n",
    "catlimit = train_limitcount\n",
    "\n",
    "\n",
    "# 对 ImageNet 分类进行分析\n",
    "# 狗分类：118种，猫分类：7种\n",
    "\n",
    "ImageNetdogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "ImageNetcats=[\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_not_animalarray(model, top, animalarray,img_paths, xsize, ysize, preprocess_input, decode_predictions):\n",
    "    '''\n",
    "    清理数据集中不是对应标签的文件\n",
    "    model:模型\n",
    "    top:可能概率前几个类型\n",
    "    animalarray: ImageNet分类集\n",
    "    img_paths:数据集路径\n",
    "    x:图片宽\n",
    "    y:图片高\n",
    "    '''\n",
    "    animals = []\n",
    "    for img_path in img_paths:\n",
    "        img = image.load_img(img_path, target_size=(xsize, ysize))\n",
    "        imgarray = image.img_to_array(img)\n",
    "        imgarray = np.expand_dims(imgarray, axis=0)\n",
    "        imgarray = preprocess_input(imgarray)\n",
    "\n",
    "        preds = model.predict(imgarray)\n",
    "        predarray = decode_predictions(preds, top=top)\n",
    "#         sorted(tmparray, key=lambda tmp: tmp[2], reverse=True) \n",
    "\n",
    "        # 判断是否有指定类型存在\n",
    "        existflag = False\n",
    "        for n in range(top):\n",
    "            animal = predarray[0][n][0]\n",
    "            if animal in animalarray:\n",
    "                existflag = True\n",
    "                break\n",
    "        if existflag == False:\n",
    "            animals.append(img_path)\n",
    "            \n",
    "    return animals\n",
    "\n",
    "# [[('n02092002', 'Scottish_deerhound', 0.21568948),('n02097130', 'giant_schnauzer', 0.074100845)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用ResNet50网络进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "ResNet50_model = ResNet50(weights='imagenet')\n",
    "\n",
    "# 不是狗的\n",
    "ResNet50_notdogs = get_not_animalarray(ResNet50_model, topparma, ImageNetdogs, dogs_list[0:doglimit], 224, 224, preprocess_input, decode_predictions)\n",
    "print(ResNet50_notdogs)\n",
    "\n",
    "# 不是猫的\n",
    "ResNet50_notcats = get_not_animalarray(ResNet50_model, topparma, ImageNetcats, cats_list[0:catlimit], 224, 224, preprocess_input, decode_predictions)\n",
    "print(ResNet50_notdogs)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用VGG19网络进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input,decode_predictions\n",
    "\n",
    "VGG19_model = VGG19(weights='imagenet')\n",
    "\n",
    "# 不是狗的\n",
    "VGG19_notdogs = get_not_animalarray(VGG19_model, topparma, ImageNetdogs, dogs_list[0:doglimit], 224, 224, preprocess_input, decode_predictions)\n",
    "print(VGG19_notdogs)\n",
    "\n",
    "# 不是猫的\n",
    "VGG19_notcats = get_not_animalarray(VGG19_model, topparma, ImageNetcats, cats_list[0:catlimit], 224, 224, preprocess_input, decode_predictions)\n",
    "print(VGG19_notcats)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用Xception网络进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input,decode_predictions\n",
    "\n",
    "Xception_model = Xception(weights='imagenet')\n",
    "\n",
    "# 不是狗的\n",
    "Xception_notdogs = get_not_animalarray(Xception_model, topparma, ImageNetdogs, dogs_list[0:doglimit], 299, 299, preprocess_input, decode_predictions)\n",
    "print(Xception_notdogs)\n",
    "\n",
    "# 不是猫的\n",
    "Xception_notcats = get_not_animalarray(Xception_model, topparma, ImageNetcats, cats_list[0:catlimit], 299, 299, preprocess_input, decode_predictions)\n",
    "print(Xception_notcats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用InceptionV3网络进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input,decode_predictions\n",
    "\n",
    "InceptionV3_model = InceptionV3(weights='imagenet')\n",
    "\n",
    "# 不是狗的\n",
    "InceptionV3_notdogs = get_not_animalarray(InceptionV3_model, topparma, ImageNetdogs, dogs_list[0:doglimit], 299, 299, preprocess_input, decode_predictions)\n",
    "print(InceptionV3_notdogs)\n",
    "\n",
    "# 不是猫的\n",
    "InceptionV3_notcats = get_not_animalarray(InceptionV3_model, topparma, ImageNetcats, cats_list[0:catlimit], 299, 299, preprocess_input, decode_predictions)\n",
    "print(InceptionV3_notcats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并结果集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['images/all/trainnew/cats/cat.10003.jpg']\n"
     ]
    }
   ],
   "source": [
    "# 合并所有的结果，取并集\n",
    "notdogs = ResNet50_notdogs + VGG19_notdogs + Xception_notdogs + InceptionV3_notdogs\n",
    "notdogs = list(set(notdogs))\n",
    "print(notdogs)\n",
    "\n",
    "notcats = ResNet50_notcats + VGG19_notcats + Xception_notcats + InceptionV3_notdogs\n",
    "notcats = list(set(notcats))\n",
    "print(notcats)\n",
    "\n",
    "\n",
    "notmatchs = notdogs + notcats\n",
    "# notmatchs = notdogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 剔除异常数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "def show_multiple_image(images):\n",
    "    '''\n",
    "    展示多组图片\n",
    "    '''\n",
    "    count = 1\n",
    "    row = len(images) / 4\n",
    "    col = 4\n",
    "    if (row < 1):\n",
    "        row = 1\n",
    "    for image in images:\n",
    "        plt.figure(num='astronaut', figsize =(12,15))  #创建一个名为astronaut的窗口,并设置大小 \n",
    "        img = plt.imread(image)  \n",
    "        if (count == 1):\n",
    "            plt.subplot(row,col,count)     #将窗口分为两行两列四个子图，则可显示四幅图片\n",
    "            plt.title(image.split(splitflag)[-1])   #第一幅图片标题l\n",
    "            plt.imshow(img)      #绘制第一幅图片\n",
    "        else:\n",
    "            plt.subplot(row,col,count)     #第三个子图\n",
    "            plt.title(image.split(splitflag)[-1])   #第一幅图片标题l\n",
    "            plt.imshow(img)      #绘制第一幅图片\n",
    "\n",
    "        if (count >= 8):\n",
    "            count += 1\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "    plt.show()   #显示窗口\n",
    "\n",
    "\n",
    "# test1=['images/all/testnew/test\\\\1.jpg', 'images/all/testnew/test\\\\10.jpg', 'images/all/testnew/test\\\\100.jpg', 'images/all/testnew/test\\\\1000.jpg']    \n",
    "# test2=['images/all/testnew/test\\\\1.jpg', 'images/all/testnew/test\\\\10.jpg', 'images/all/testnew/test\\\\100.jpg', 'images/all/testnew/test\\\\1000.jpg']    \n",
    "# test3=['images/all/testnew/test\\\\1.jpg', 'images/all/testnew/test\\\\10.jpg', 'images/all/testnew/test\\\\100.jpg', 'images/all/testnew/test\\\\1000.jpg']    \n",
    "# test4=['images/all/testnew/test\\\\101.jpg', 'images/all/testnew/test\\\\102.jpg', 'images/all/testnew/test\\\\100.jpg', 'images/all/testnew/test\\\\1000.jpg']    \n",
    "# test5=[]\n",
    "# test = test1+ test2 + test3 + test4\n",
    "# print(len(notmatchs))\n",
    "# show_multiple_image(notmatchs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 剔除异常数据\n",
    "file_move(notmatchs, notmatch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from keras.layers import GlobalAveragePooling2D,Dense\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import Adagrad\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据总数：19\n",
      "15\n",
      "4\n",
      "测试集数据总数：100\n"
     ]
    }
   ],
   "source": [
    "# 加载 train 测试数据集\n",
    "train_data = load_files(train_path)\n",
    "\n",
    "# 加载 test 测试数据集\n",
    "test_data = load_files(testnew_path)    \n",
    "\n",
    "trainall_file = np.array(train_data['filenames'])\n",
    "trainall_targets = np_utils.to_categorical(np.array(train_data['target']), 2)\n",
    "# print(type(train_data))\n",
    "# print(train_targets)\n",
    "\n",
    "# 展示训练数据集\n",
    "print('训练集数据总数：%d' % len(trainall_file))\n",
    "\n",
    "\n",
    "# 将原来的训练数据分割成训练数据集和验证数据集，比例为20%\n",
    "train_files, valid_files, train_targets, valid_targets = train_test_split(trainall_file, trainall_targets, test_size=0.2)\n",
    "\n",
    "print(len(train_files))\n",
    "print(len(valid_files))\n",
    "# print(tarin_targets)\n",
    "# print(valid_targets)\n",
    "\n",
    "\n",
    "test_files = np.array(test_data['filenames'])\n",
    "test_targets = np_utils.to_categorical(np.array(test_data['target']), 1)\n",
    "\n",
    "# 展示测试数据集\n",
    "print('测试集数据总数：%d' % len(test_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 图像预处理\n",
    "\n",
    "通过对每张图像的像素值除以299，我们对图像实现了归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile  \n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "#     print(img_path)\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    img = image.load_img(img_path,target_size=(299,299))\n",
    "    \n",
    "    #将PIL.Image.Image类型转化为格式为(299,299,3)的3维张量\n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "    #将3维张量转化为格式为(1, 299, 299, 3) 的4维张量并返回\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "# img_path='images/all/train/trainnew/cats/cat.4424.jpg'\n",
    "# path_to_tensor(img_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-22 02:43:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 15/15 [00:00<00:00, 323.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end time:2018-09-22 02:43:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 训练集预处理\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/127.5 - 1\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 276.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-22 02:43:06\n",
      "end time:2018-09-22 02:43:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 验证集预处理\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/127.5 - 1\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-22 02:43:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 331.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end time:2018-09-22 02:43:07\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 测试集预处理\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/127.5 - 1\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2 构建模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 训练模型\n",
    "\n",
    "训练 InceptionV3 模型\n",
    "\n",
    "训练 Xception 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "\n",
    "#epochs = 300\n",
    "epochs = 40\n",
    "batch_size = 64\n",
    "patience=10\n",
    "\n",
    "# logloss 趋势图\n",
    "def show_logloss(history_callback):\n",
    "    plt.plot(history_callback.history['loss'])\n",
    "    plt.plot(history_callback.history['val_loss'])\n",
    "    plt.title(\"model loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"loss\",\"val_loss\"],loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 准确率趋势图\n",
    "def show_acc(history_callback):\n",
    "    plt.plot(history_callback.history['acc'])\n",
    "    plt.plot(history_callback.history['val_acc'])\n",
    "    plt.title(\"model acc\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"acc\",\"val_acc\"],loc=\"upper left\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.构建不带分类器的预训练模型\n",
    "base_model = InceptionV3(weights='imagenet',include_top=False) \n",
    "# base_model = Xception(weights='imagenet',include_top=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.添加全局平均池化层\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.全连接层，可选，如果精度够用则可以不加\n",
    "x = Dense(1024, activation='relu')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. 添加一个分类器，使用 1 个神经元，sigmoid激活函数\n",
    "predictions = Dense(2, activation='sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 构建我们需要训练的完整模型\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 支持\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "# '''\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "# '''\n",
    "\n",
    "# model = multi_gpu_model(model, gpus=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-174-e64a334a4d37>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-174-e64a334a4d37>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    #     print(i, layer.name, layer.trainable)\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# 6.首先只训练顶部的几层（随机初始化的层），锁住所有 InceptionV3d 卷积层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-22 02:28:16\n",
      "end time:2018-09-22 02:28:16\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 7.编译模型（一定要在锁层以后操作）\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-22 02:28:16\n",
      "Train on 1 samples, validate on 1 samples\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 2s - loss: 0.5910 - acc: 1.0000 - val_loss: 4.7745 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 1s - loss: 2.0325e-05 - acc: 1.0000 - val_loss: 4.7241 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 1s - loss: 2.0147e-05 - acc: 1.0000 - val_loss: 4.6768 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 1s - loss: 1.9968e-05 - acc: 1.0000 - val_loss: 4.6297 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 1s - loss: 1.9729e-05 - acc: 1.0000 - val_loss: 4.5839 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 1s - loss: 1.9551e-05 - acc: 1.0000 - val_loss: 4.5416 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 1s - loss: 1.9312e-05 - acc: 1.0000 - val_loss: 4.5013 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 1s - loss: 1.9074e-05 - acc: 1.0000 - val_loss: 4.4629 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 1s - loss: 1.8895e-05 - acc: 1.0000 - val_loss: 4.4256 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 1s - loss: 1.8656e-05 - acc: 1.0000 - val_loss: 4.3903 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 1s - loss: 1.8418e-05 - acc: 1.0000 - val_loss: 4.3576 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 1s - loss: 1.8180e-05 - acc: 1.0000 - val_loss: 4.3256 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 1s - loss: 1.7941e-05 - acc: 1.0000 - val_loss: 4.2967 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 1s - loss: 1.7643e-05 - acc: 1.0000 - val_loss: 4.2683 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 1s - loss: 1.7405e-05 - acc: 1.0000 - val_loss: 4.2407 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 2s - loss: 1.7166e-05 - acc: 1.0000 - val_loss: 4.2144 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 1s - loss: 1.6868e-05 - acc: 1.0000 - val_loss: 4.1895 - val_acc: 0.0000e+00\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 1s - loss: 1.6630e-05 - acc: 1.0000 - val_loss: 4.1664 - val_acc: 0.0000e+00\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 1s - loss: 1.6332e-05 - acc: 1.0000 - val_loss: 4.1448 - val_acc: 0.0000e+00\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 1s - loss: 1.6093e-05 - acc: 1.0000 - val_loss: 4.1242 - val_acc: 0.0000e+00\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 1s - loss: 1.5795e-05 - acc: 1.0000 - val_loss: 4.1043 - val_acc: 0.0000e+00\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 1s - loss: 1.5497e-05 - acc: 1.0000 - val_loss: 4.0849 - val_acc: 0.0000e+00\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 1s - loss: 1.5259e-05 - acc: 1.0000 - val_loss: 4.0665 - val_acc: 0.0000e+00\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 1s - loss: 1.4961e-05 - acc: 1.0000 - val_loss: 4.0489 - val_acc: 0.0000e+00\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 1s - loss: 1.4663e-05 - acc: 1.0000 - val_loss: 4.0313 - val_acc: 0.0000e+00\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 1s - loss: 1.4365e-05 - acc: 1.0000 - val_loss: 4.0149 - val_acc: 0.0000e+00\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 1s - loss: 1.4067e-05 - acc: 1.0000 - val_loss: 3.9997 - val_acc: 0.0000e+00\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 1s - loss: 1.3769e-05 - acc: 1.0000 - val_loss: 3.9855 - val_acc: 0.0000e+00\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 1s - loss: 1.3471e-05 - acc: 1.0000 - val_loss: 3.9712 - val_acc: 0.0000e+00\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 1s - loss: 1.3173e-05 - acc: 1.0000 - val_loss: 3.9581 - val_acc: 0.0000e+00\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 1s - loss: 1.2934e-05 - acc: 1.0000 - val_loss: 3.9460 - val_acc: 0.0000e+00\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 1s - loss: 1.2696e-05 - acc: 1.0000 - val_loss: 3.9343 - val_acc: 0.0000e+00\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 1s - loss: 1.2398e-05 - acc: 1.0000 - val_loss: 3.9227 - val_acc: 0.0000e+00\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 1s - loss: 1.2159e-05 - acc: 1.0000 - val_loss: 3.9115 - val_acc: 0.0000e+00\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 1s - loss: 1.1921e-05 - acc: 1.0000 - val_loss: 3.9007 - val_acc: 0.0000e+00\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 1s - loss: 1.1623e-05 - acc: 1.0000 - val_loss: 3.8905 - val_acc: 0.0000e+00\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 1s - loss: 1.1385e-05 - acc: 1.0000 - val_loss: 3.8811 - val_acc: 0.0000e+00\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 1s - loss: 1.1146e-05 - acc: 1.0000 - val_loss: 3.8725 - val_acc: 0.0000e+00\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 1s - loss: 1.0848e-05 - acc: 1.0000 - val_loss: 3.8652 - val_acc: 0.0000e+00\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 1s - loss: 1.0610e-05 - acc: 1.0000 - val_loss: 3.8579 - val_acc: 0.0000e+00\n",
      "end time:2018-09-22 02:29:45\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 8. 在新的数据集上训练几代\n",
    "# early stoppping \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# monitor: 需要监视的变量\n",
    "# patience:在发现变量没有变化后的多少个epoch停止\n",
    "# verbose:信息展示模式\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "callback_lists = [tensorboard, early_stopping]\n",
    "history_callback = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "         epochs=epochs, batch_size=batch_size, verbose=1, callbacks=callback_lists)\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a661e5400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 展示logloss趋势\n",
    "show_logloss(history_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_8\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d_197\n",
      "13 block2_pool\n",
      "14 batch_normalization_197\n",
      "15 add_57\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_198\n",
      "23 block3_pool\n",
      "24 batch_normalization_198\n",
      "25 add_58\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_199\n",
      "33 block4_pool\n",
      "34 batch_normalization_199\n",
      "35 add_59\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_60\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_61\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_62\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_63\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_64\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_65\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_66\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_67\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_200\n",
      "123 block13_pool\n",
      "124 batch_normalization_200\n",
      "125 add_68\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n"
     ]
    }
   ],
   "source": [
    "# 9.现在顶层应该训练好了，开始微调 InceptionV3的卷积层。\n",
    "#锁住底下的几层，然后训练其余的顶层。查看每一层的名字和层号，看看应该锁多少层\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10.我们选择训练最上面的两个 Inception block, 锁住前面249层，然后放开之后的层\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile ok\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# 11.重新编译模型，使上面的修改生效，设置一个很低的学习率:lr=0.001，使用SGD来微调\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print('compile ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-22 02:23:59\n",
      "Train on 1 samples, validate on 1 samples\n",
      "Epoch 1/40\n",
      "Epoch 00000: val_loss improved from inf to 3.82289, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 16s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.8229 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "Epoch 00001: val_loss improved from 3.82289 to 3.80607, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.8061 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "Epoch 00002: val_loss improved from 3.80607 to 3.78982, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.7898 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "Epoch 00003: val_loss improved from 3.78982 to 3.77397, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.7740 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "Epoch 00004: val_loss improved from 3.77397 to 3.75827, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.7583 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "Epoch 00005: val_loss improved from 3.75827 to 3.74270, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.7427 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "Epoch 00006: val_loss improved from 3.74270 to 3.72779, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.7278 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "Epoch 00007: val_loss improved from 3.72779 to 3.71339, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 3s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.7134 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "Epoch 00008: val_loss improved from 3.71339 to 3.69933, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6993 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "Epoch 00009: val_loss improved from 3.69933 to 3.68523, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6852 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "Epoch 00010: val_loss improved from 3.68523 to 3.67208, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6721 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "Epoch 00011: val_loss improved from 3.67208 to 3.65985, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6599 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "Epoch 00012: val_loss improved from 3.65985 to 3.64824, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6482 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "Epoch 00013: val_loss improved from 3.64824 to 3.63745, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6374 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "Epoch 00014: val_loss improved from 3.63745 to 3.62695, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6269 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "Epoch 00015: val_loss improved from 3.62695 to 3.61658, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6166 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "Epoch 00016: val_loss improved from 3.61658 to 3.60578, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.6058 - val_acc: 0.0000e+00\n",
      "Epoch 18/40\n",
      "Epoch 00017: val_loss improved from 3.60578 to 3.59469, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5947 - val_acc: 0.0000e+00\n",
      "Epoch 19/40\n",
      "Epoch 00018: val_loss improved from 3.59469 to 3.58354, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5835 - val_acc: 0.0000e+00\n",
      "Epoch 20/40\n",
      "Epoch 00019: val_loss improved from 3.58354 to 3.57305, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5731 - val_acc: 0.0000e+00\n",
      "Epoch 21/40\n",
      "Epoch 00020: val_loss improved from 3.57305 to 3.56305, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5631 - val_acc: 0.0000e+00\n",
      "Epoch 22/40\n",
      "Epoch 00021: val_loss improved from 3.56305 to 3.55344, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5534 - val_acc: 0.0000e+00\n",
      "Epoch 23/40\n",
      "Epoch 00022: val_loss improved from 3.55344 to 3.54450, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5445 - val_acc: 0.0000e+00\n",
      "Epoch 24/40\n",
      "Epoch 00023: val_loss improved from 3.54450 to 3.53547, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5355 - val_acc: 0.0000e+00\n",
      "Epoch 25/40\n",
      "Epoch 00024: val_loss improved from 3.53547 to 3.52659, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5266 - val_acc: 0.0000e+00\n",
      "Epoch 26/40\n",
      "Epoch 00025: val_loss improved from 3.52659 to 3.51810, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5181 - val_acc: 0.0000e+00\n",
      "Epoch 27/40\n",
      "Epoch 00026: val_loss improved from 3.51810 to 3.50967, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5097 - val_acc: 0.0000e+00\n",
      "Epoch 28/40\n",
      "Epoch 00027: val_loss improved from 3.50967 to 3.50089, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.5009 - val_acc: 0.0000e+00\n",
      "Epoch 29/40\n",
      "Epoch 00028: val_loss improved from 3.50089 to 3.49251, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4925 - val_acc: 0.0000e+00\n",
      "Epoch 30/40\n",
      "Epoch 00029: val_loss improved from 3.49251 to 3.48453, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4845 - val_acc: 0.0000e+00\n",
      "Epoch 31/40\n",
      "Epoch 00030: val_loss improved from 3.48453 to 3.47671, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4767 - val_acc: 0.0000e+00\n",
      "Epoch 32/40\n",
      "Epoch 00031: val_loss improved from 3.47671 to 3.46917, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4692 - val_acc: 0.0000e+00\n",
      "Epoch 33/40\n",
      "Epoch 00032: val_loss improved from 3.46917 to 3.46232, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4623 - val_acc: 0.0000e+00\n",
      "Epoch 34/40\n",
      "Epoch 00033: val_loss improved from 3.46232 to 3.45584, saving model to saved_models/weights.best.Inception.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4558 - val_acc: 0.0000e+00\n",
      "Epoch 35/40\n",
      "Epoch 00034: val_loss improved from 3.45584 to 3.44973, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4497 - val_acc: 0.0000e+00\n",
      "Epoch 36/40\n",
      "Epoch 00035: val_loss improved from 3.44973 to 3.44369, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4437 - val_acc: 0.0000e+00\n",
      "Epoch 37/40\n",
      "Epoch 00036: val_loss improved from 3.44369 to 3.43804, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4380 - val_acc: 0.0000e+00\n",
      "Epoch 38/40\n",
      "Epoch 00037: val_loss improved from 3.43804 to 3.43273, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4327 - val_acc: 0.0000e+00\n",
      "Epoch 39/40\n",
      "Epoch 00038: val_loss improved from 3.43273 to 3.42742, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4274 - val_acc: 0.0000e+00\n",
      "Epoch 40/40\n",
      "Epoch 00039: val_loss improved from 3.42742 to 3.42200, saving model to saved_models/weights.best.Inception.hdf5\n",
      "1/1 [==============================] - 2s - loss: 2.2829e-05 - acc: 1.0000 - val_loss: 3.4220 - val_acc: 0.0000e+00\n",
      "end time:2018-09-22 02:26:08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 12.继续训练模型，训练最后两个 Inception block 和两个全连接层\n",
    "Inceptionfile_hdf5 ='saved_models/weights.best.Inception.hdf5'\n",
    "\n",
    "# 模型保存\n",
    "checkpointer = ModelCheckpoint(filepath=Inceptionfile_hdf5, verbose=1, save_best_only=True)\n",
    "\n",
    "# 可视化\n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "\n",
    "# 自动停止训练\n",
    "# monitor: 需要监视的变量\n",
    "# patience:在发现变量没有变化后的多少个epoch停止\n",
    "# verbose:信息展示模式\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n",
    "\n",
    "\n",
    "callback_lists = [tensorboard, checkpointer, early_stopping]\n",
    "\n",
    "# # 训练模型\n",
    "history_callback = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "         epochs=epochs, batch_size=batch_size,callbacks=callback_lists,shuffle='True',verbose=1)\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwczMMv8fbRuDRtVu53IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a90c22358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 展示logloss趋势\n",
    "show_logloss(history_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 测试模型\n",
    "\n",
    "在测试数据集上试用训练后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018.09.22 02:26:08\n",
      "1/1 [==============================] - 2s\n",
      "images/all/testnew\n",
      "Found 100 images belonging to 1 classes.\n",
      "end time:2018.09.22 02:26:12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "## 加载具有最好验证loss的模型\n",
    "starttime = time.strftime('start time:%Y.%m.%d %H:%M:%S',time.localtime(time.time()))\n",
    "print (starttime)\n",
    "\n",
    "model.load_weights(Inceptionfile_hdf5)\n",
    "\n",
    "# # 获取测试数据集中每一个图像所预测的狗品种的index\n",
    "# dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "# # 报告测试准确率\n",
    "# test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "# print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_tensors, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "print(testnew_path)\n",
    "test_generator = gen.flow_from_directory(testnew_path, (299, 299), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "endtime = time.strftime('end time:%Y.%m.%d %H:%M:%S',time.localtime(time.time()))\n",
    "print (endtime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-f1d959850fdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i][0])\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 提交 kaggle测试得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
