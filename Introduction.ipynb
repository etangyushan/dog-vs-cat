{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 探索数据\n",
    "\n",
    "\n",
    "数据集使用 kaggle 数据集，解压后存放在images目录下\n",
    "- 训练数据集路径：\n",
    "images/all/train\n",
    "- 测试数据集路径：\n",
    "images/all/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 整理数据集\n",
    " \n",
    "这里由于 trian 文件夹下的猫和狗的数据是混在一起的，需要将猫和狗的图片分别存储。\n",
    "\n",
    "图片的命名规则：类别.编码.jpg\n",
    "\n",
    "**注意：这里的处理只需要运行一次即可**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "def create_dir(path):\n",
    "    '''\n",
    "    创建文件夹\n",
    "    '''\n",
    "    if (os.path.exists(path) == False):\n",
    "        os.mkdir (path)\n",
    "    else:\n",
    "        print('文件夹已经存在：%s' % path)\n",
    "\n",
    "# 限制训练文件数量,0不限制\n",
    "def copy_image_bytype(srcfiles, path, limitcount = 0):\n",
    "    '''\n",
    "    将猫狗文件分别拷贝到不同文件夹下\n",
    "    '''\n",
    "\n",
    "    filenames = [item.split(\"/\")[-1] for item in sorted(srcfiles)]\n",
    "    for src,name in zip(srcfiles,filenames):\n",
    "        \n",
    "        dst = path + '/' + name\n",
    "        if (os.path.exists(dst) == False):\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "        # 跳出循环\n",
    "        limitcount = limitcount - 1\n",
    "        if (limitcount == 0):\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹已经存在：images/all\n",
      "文件夹已经存在：images/all/trainnew\n",
      "文件夹已经存在：images/all/trainnew/dogs\n",
      "文件夹已经存在：images/all/trainnew/cats\n",
      "文件夹已经存在：images/all/testnew\n",
      "文件夹已经存在：images/all/testnew/test\n"
     ]
    }
   ],
   "source": [
    "# 创建文件夹\n",
    "all_path = 'images/all'\n",
    "train_path = 'images/all/trainnew'\n",
    "dog_path = 'images/all/trainnew/dogs'\n",
    "cat_path = 'images/all/trainnew/cats'\n",
    "\n",
    "testnew_path = 'images/all/testnew'\n",
    "test_path = 'images/all/testnew/test'\n",
    "\n",
    "create_dir(all_path)\n",
    "\n",
    "create_dir(train_path)\n",
    "create_dir(dog_path)\n",
    "create_dir(cat_path)\n",
    "\n",
    "create_dir(testnew_path)\n",
    "create_dir(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 total dog categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理狗\n",
    "dogs_list = glob(\"images/train/dog.*\")\n",
    "\n",
    "# 打印数据统计描述\n",
    "# print(dogs_list[0])\n",
    "dog_filenames = [item.split(\"/\")[-1] for item in sorted(dogs_list)]\n",
    "print('There are %d total dog categories.' % len(dogs_list))\n",
    "\n",
    "# 整理狗数据\n",
    "# copy_image_bytype(dogs_list, dog_path, 10000)\n",
    "copy_image_bytype(dogs_list, dog_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 total cat categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理猫\n",
    "cats_list = glob(\"images/train/cat.*\")\n",
    "\n",
    "# 打印数据统计描述\n",
    "cat_filenames = [item.split(\"/\")[-1] for item in sorted(cats_list)]\n",
    "print('There are %d total cat categories.' % len(cat_filenames))\n",
    "\n",
    "# 整理猫数据\n",
    "# copy_image_bytype(cats_list, cat_path, 10000)\n",
    "copy_image_bytype(cats_list, cat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 total test categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理测试数据\n",
    "test_list = glob(\"images/test/*\")\n",
    "\n",
    "# 打印数据统计描述\n",
    "test_filenames = [item.split(\"/\")[-1] for item in sorted(test_list)]\n",
    "print('There are %d total test categories.' % len(test_filenames))\n",
    "\n",
    "# 整理猫数据\n",
    "# copy_image_bytype(test_list, test_path, 5000)\n",
    "copy_image_bytype(test_list, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.2 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 加载 train 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据总数：25000\n"
     ]
    }
   ],
   "source": [
    "# 加载 train 测试数据集\n",
    "train_data = load_files(train_path)\n",
    "trainall_file = np.array(train_data['filenames'])\n",
    "trainall_targets = np_utils.to_categorical(np.array(train_data['target']), 2)\n",
    "# print(type(train_data))\n",
    "# print(train_targets)\n",
    "\n",
    "# 展示训练数据集\n",
    "print('训练集数据总数：%d' % len(trainall_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 加载 test 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集数据总数：12500\n"
     ]
    }
   ],
   "source": [
    "# 加载 test 测试数据集\n",
    "test_data = load_files(testnew_path)\n",
    "test_files = np.array(test_data['filenames'])\n",
    "test_targets = np_utils.to_categorical(np.array(test_data['target']), 1)\n",
    "\n",
    "# 展示测试数据集\n",
    "print('测试集数据总数：%d' % len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode as spmode\n",
    "\n",
    "def draw_hist(mylist, title, xlabel, ylabel, xmin, xmax, ymin, ymax):\n",
    "    '''\n",
    "    绘制直方图，参数依次为list,抬头,X轴标签,Y轴标签,XY轴的范围\n",
    "    '''\n",
    "    plt.hist(mylist, 100)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def show_filesize(paths):\n",
    "    filesizes = []\n",
    "    for path in paths:\n",
    "        filesize = os.path.getsize(path)\n",
    "        filesizes.append(filesize)\n",
    "    \n",
    "    title = 'file size distribute'\n",
    "    xlabel = 'file size'\n",
    "    ylabel = 'file count'\n",
    "    xmin = np.min(filesizes)\n",
    "    xmax = np.max(filesizes)\n",
    "    ymin = 0\n",
    "    ymax = 1200\n",
    "\n",
    "    # train 中文件的的最小值、最大值、中位数、众数\n",
    "    train_min = np.min(filesizes)\n",
    "    print('train 中文件的的最小值:', train_min)\n",
    "\n",
    "    train_max = np.max(filesizes)\n",
    "    print('train 中文件的的最大值:', train_max)\n",
    "\n",
    "    train_median = np.median(filesizes)\n",
    "    print('train 中文件的的中位数:', train_median)\n",
    "\n",
    "    train_mode = spmode(filesizes)\n",
    "    print('train 中文件的的众数:', train_mode)\n",
    "\n",
    "    draw_hist(filesizes, title, xlabel, ylabel, xmin, xmax, ymin, ymax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 中文件的的最小值: 1106\n",
      "train 中文件的的最大值: 93323\n",
      "train 中文件的的中位数: 22165.5\n",
      "train 中文件的的众数: ModeResult(mode=array([20918]), count=array([6]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMXBIknr5/7Q/jr/qHpI7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3f3eabd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 文件大小的分布\n",
    "show_filesize(trainall_file)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 分割训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 将原来的训练数据分割成训练数据集和验证数据集，比例为20%\n",
    "train_files, valid_files, train_targets, valid_targets = train_test_split(trainall_file, trainall_targets, test_size=0.2)\n",
    "\n",
    "print(len(train_files))\n",
    "print(len(valid_files))\n",
    "# print(tarin_targets)\n",
    "# print(valid_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 图像预处理\n",
    "\n",
    "通过对每张图像的像素值除以299，我们对图像实现了归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "#     print(img_path)\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    img = image.load_img(img_path,target_size=(299,299))\n",
    "    \n",
    "    #将PIL.Image.Image类型转化为格式为(299,299,3)的3维张量\n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "    #将3维张量转化为格式为(1, 299, 299, 3) 的4维张量并返回\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "# img_path='images/all/train/trainnew/cats/cat.4424.jpg'\n",
    "# path_to_tensor(img_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:05<00:00, 304.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# 训练集预处理\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/127.5 - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:14<00:00, 342.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# 验证集预处理\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/127.5 - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:38<00:00, 325.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# 测试集预处理\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/127.5 - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2 构建模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 训练模型\n",
    "\n",
    "训练 InceptionV3 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.构建不带分类器的预训练模型\n",
    "base_model = InceptionV3(weights='imagenet',include_top=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.添加全局平均池化层\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.全连接层，可选，如果精度够用则可以不加\n",
    "# x = Dense(1024, activation='relu')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. 添加一个分类器，使用 1 个神经元，sigmoid激活函数\n",
    "predictions = Dense(2, activation='sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 构建我们需要训练的完整模型\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.首先只训练顶部的几层（随机初始化的层），锁住所有 InceptionV3d 卷积层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.编译模型（一定要在锁层以后操作）\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 2341s - loss: 0.2965 - val_loss: 0.1716\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 2341s - loss: 0.2959 - val_loss: 0.1201\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 2342s - loss: 0.2850 - val_loss: 0.1726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3e563d550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. 在新的数据集上训练几代\n",
    "model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "         epochs=3, batch_size=3, verbose=1)\n",
    "# model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "#          epochs=3, batch_size=5, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.现在顶层应该训练好了，开始微调 InceptionV3的卷积层。\n",
    "#锁住底下的几层，然后训练其余的顶层。查看每一层的名字和层号，看看应该锁多少层\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10.我们选择训练最上面的两个 Inception block, 锁住前面249层，然后放开之后的层\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile ok\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# 11.重新编译模型，使上面的修改生效，设置一个很低的学习率，使用SGD来微调\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print('compile ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "   65/20000 [..............................] - ETA: 2717s - loss: 0.0349 - acc: 0.9846"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# 12.继续训练模型，训练最后两个 Inception block 和两个全连接层\n",
    "Inceptionfile_hdf5 ='saved_models/weights.best.Inception.hdf5'\n",
    "\n",
    "# 模型保存\n",
    "checkpointer = ModelCheckpoint(filepath=Inceptionfile_hdf5, verbose=1, save_best_only=True)\n",
    "\n",
    "# 可视化\n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "\n",
    "callback_lists = [tensorboard, checkpointer]\n",
    "\n",
    "# # 训练模型\n",
    "# history_callback = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "#          epochs=20, batch_size=20,callbacks=callback_lists,shuffle='True',verbose='True')\n",
    "history_callback = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "         epochs=3, batch_size=5,callbacks=callback_lists,shuffle='True',verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 测试模型\n",
    "\n",
    "在测试数据集上试用训练后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 加载具有最好验证loss的模型\n",
    "model.load_weights(Inceptionfile_hdf5)\n",
    "\n",
    "# 获取测试数据集中每一个图像所预测的狗品种的index\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# 报告测试准确率\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "loss_history = history_callback.history['loss']\n",
    "print(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗大战\n",
    "\n",
    "## 注意：请不要直接使用网上公开的代码\n",
    "\n",
    "[Dogs vs. Cats Redux: Kernels Edition\n",
    "](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)\n",
    "\n",
    "![](dogvscat.png)\n",
    "\n",
    "## AWS\n",
    "\n",
    "由于此项目要求的计算量较大，建议使用亚马逊 p3.2xlarge 云服务器来完成该项目，在使用 p3 之前，你可以先用 p2.xlarge 练手，参考：[在aws上配置深度学习主机 ](https://zhuanlan.zhihu.com/p/25066187)，[利用AWS学习深度学习](https://zhuanlan.zhihu.com/p/33176260)。\n",
    "\n",
    "## 描述\n",
    "\n",
    "使用深度学习方法识别一张图片是猫还是狗。\n",
    "\n",
    "* 输入：一张彩色图片\n",
    "* 输出：狗的概率\n",
    "\n",
    "## 数据\n",
    "\n",
    "此数据集可以从 kaggle 上下载。[Dogs vs. Cats Redux: Kernels Edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)\n",
    "\n",
    "此外还有一个数据集也非常好，可以作为扩充数据集或是做检测/分割问题：[The Oxford-IIIT Pet Dataset](http://www.robots.ox.ac.uk/~vgg/data/pets/)\n",
    "\n",
    "![](http://www.robots.ox.ac.uk/~vgg/data/pets/pet_annotations.jpg)\n",
    "\n",
    "## 建议\n",
    "\n",
    "建议使用 OpenCV, tensorflow, Keras 完成该项目。其他的工具也可以尝试，比如 caffe, mxnet 等。\n",
    "\n",
    "* [OpenCV](https://github.com/opencv/opencv)\n",
    "* [OpenCV python tutorials](http://docs.opencv.org/3.1.0/d6/d00/tutorial_py_root.html)\n",
    "* [tensorflow](https://github.com/tensorflow/tensorflow)\n",
    "* [Keras](https://github.com/fchollet/keras)\n",
    "* [Keras 中文文档](http://keras-cn.readthedocs.io/)\n",
    "\n",
    "### 建议模型\n",
    "\n",
    "如果你不知道如何去构建你的模型，可以尝试以下的模型，后面的数字代表年份和月份：\n",
    "\n",
    "* [VGGNet](https://arxiv.org/abs/1409.1556) 14.09\n",
    "* [ResNet](https://arxiv.org/abs/1512.03385) 15.12\n",
    "* [Inception v3](https://arxiv.org/abs/1512.00567) 15.12\n",
    "* [InceptionResNetV2](https://arxiv.org/abs/1602.07261) 16.02\n",
    "* [DenseNet](https://arxiv.org/abs/1608.06993) 16.08\n",
    "* [Xception](https://arxiv.org/abs/1610.02357) 16.10\n",
    "* [NASNet](https://arxiv.org/abs/1707.07012) 17.07\n",
    "\n",
    "参考 Keras 文档：[Documentation for individual models](https://keras.io/applications/#documentation-for-individual-models)\n",
    "\n",
    "# 最低要求\n",
    "\n",
    "本项目的最低要求是 kaggle Public Leaderboard 前10%。\n",
    "\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/leaderboard\n",
    "\n",
    "## 应用(可选)(推荐)\n",
    "\n",
    "应用形式多种多样，可以是在本地调用摄像头跑的程序，也可以网页的，也可以是 iOS APP 或 Android APP，甚至可以是微信公众号。\n",
    "\n",
    "### 网页应用\n",
    "\n",
    "推荐的工具：\n",
    "\n",
    "* [Flask](https://github.com/pallets/flask)\n",
    "* [Flask 中文文档](http://docs.jinkan.org/docs/flask/)\n",
    "\n",
    "### 微信公众号\n",
    "\n",
    "可以参考这个例子：[微信数字识别](https://github.com/ypwhs/wechat_digit_recognition)。\n",
    "\n",
    "网页接口部分可以参考 [Flask](https://github.com/pallets/flask) 而不必用 python cgi。\n",
    "\n",
    "### iOS\n",
    "\n",
    "如果你使用 Keras 完成该项目，可以直接使用 Apple 提供的 [Core ML Tools](https://developer.apple.com/documentation/coreml/converting_trained_models_to_core_ml) 把训练出来的 Keras 模型直接转为 iOS 可以使用的模型。\n",
    "\n",
    "当然在 iOS 平台上你也可以使用 [MetalPerformanceShaders](https://developer.apple.com/reference/metalperformanceshaders) 来实现卷积神经网络。\n",
    "\n",
    "这里有一个 [Inception v3](https://github.com/shu223/iOS-10-Sampler/blob/master/iOS-10-Sampler/Samples/Inception3Net.swift) 在 iOS 上跑的例子，你可以参考，不过我们还是建议直接用上面的工具将 Keras 的模型转为 iOS 直接可以使用的模型。\n",
    "\n",
    "![](https://raw.githubusercontent.com/shu223/iOS-10-Sampler/master/README_resources/imagerecog.gif)\n",
    "\n",
    "OpenCV 的 iOS Framework 文件可以直接在这里下载：[OpenCV releases](https://github.com/opencv/opencv/releases)。这里有一份教程，可以轻松入门：[turorial_hello](https://docs.opencv.org/master/d7/d88/tutorial_hello.html)\n",
    "\n",
    "最终效果可以参考这个 app ：[PetOrNot](https://itunes.apple.com/cn/app/petornot/id926645155)\n",
    "\n",
    "![PetOrNot](PetOrNot.jpeg)\n",
    "\n",
    "### Android\n",
    "\n",
    "在 Android 上运行 tensorflow 可以参考 [android tensorflow](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)。\n",
    "\n",
    "在 Android 上运行 OpenCV 可以参考 [OpenCV4Android SDK](http://docs.opencv.org/master/da/d2a/tutorial_O4A_SDK.html)。\n",
    "\n",
    "## 评估\n",
    "\n",
    "你的项目会由优达学城项目评审师依照[机器学习毕业项目要求](https://review.udacity.com/#!/rubrics/273/view)来评审。请确定你已完整的读过了这个要求，并在提交前对照检查过了你的项目。提交项目必须满足所有要求中每一项才能算作项目通过。\n",
    "\n",
    "## 提交\n",
    "\n",
    "* PDF 报告文件\n",
    "* 数据预处理代码（jupyter notebook）\n",
    "* 模型训练代码（jupyter notebook）\n",
    "* notebook 导出的 html 文件\n",
    "* 应用代码（可选）\n",
    "* 包含使用的库，机器硬件，机器操作系统，训练时间等数据的 README 文档（建议使用 Markdown ）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
