{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 探索数据\n",
    "\n",
    "\n",
    "数据集使用 kaggle 数据集，解压后存放在images目录下\n",
    "- 训练数据集路径：\n",
    "images/train\n",
    "- 测试数据集路径：\n",
    "images/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 整理数据集\n",
    " \n",
    "这里由于 trian 文件夹下的猫和狗的数据是混在一起的，需要将猫和狗的图片分别存储。\n",
    "\n",
    "图片的命名规则：类别.编码.jpg\n",
    "\n",
    "**注意：这里的处理只需要运行一次即可**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/usr/lib/python35.zip', '/usr/lib/python3.5', '/usr/lib/python3.5/plat-x86_64-linux-gnu', '/usr/lib/python3.5/lib-dynload', '/usr/local/lib/python3.5/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.5/dist-packages/IPython/extensions', '/root/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "# sys.path.append(\"/home/ubuntu/anaconda3/envs/dog-project/lib/python3.6/site-packages\")\n",
    "# sys.path.append(\"/home/ubuntu/anaconda3/pkgs/tensorflow-gpu-base-1.3.0-py36cuda8.0cudnn6.0_0/lib/python3.6/site-packages\")\n",
    "# sys.path.append(\"/home/ubuntu/anaconda3/pkgs/tensorflow-gpu-base-1.3.0-py36cuda8.0cudnn6.0_0/lib/python3.6/site-packages/tensorflow/contrib/keras/api\")\n",
    "# sys.path.append(\"/home/ubuntu/anaconda3/pkgs/tensorflow-gpu-base-1.3.0-py36cuda8.0cudnn6.0_0/lib/python3.6/site-packages\")\n",
    "# print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.stats import mode as spmode\n",
    "import platform\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from keras.layers import GlobalAveragePooling2D,Dense\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import Adagrad\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "import h5py\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "\n",
    "print(platform.system())\n",
    "\n",
    "notmatch_path='images/notmatchs'\n",
    "notmatch_txt = 'notmatchs.txt'\n",
    "all_path = 'images/all'\n",
    "train_path = 'images/all/trainnew'\n",
    "dog_path = 'images/all/trainnew/dogs'\n",
    "\n",
    "\n",
    "testnew_path = 'images/all/testnew'\n",
    "test_path = 'images/all/testnew/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载特征向量\n",
    "# !wget -P saved_models/  https://github.com/ypwhs/dogs_vs_cats/releases/download/gap/gap_InceptionV3.h5\n",
    "# !wget -P saved_models/  https://github.com/ypwhs/dogs_vs_cats/releases/download/gap/gap_ResNet50.h5\n",
    "# !wget -P saved_models/  https://github.com/ypwhs/dogs_vs_cats/releases/download/gap/gap_Xception.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows分隔符\n",
    "splitflag = \"\\\\\"\n",
    "if (platform.system() == 'Linux'):\n",
    "    splitflag = \"/\"\n",
    "\n",
    "#处理的样本量\n",
    "train_limitcount = 12500\n",
    "test_limitcount = 12500 #不限制个数全部使用\n",
    "\n",
    "def create_dir(path):\n",
    "    '''\n",
    "    创建文件夹\n",
    "    '''\n",
    "    if (os.path.exists(path) == False):\n",
    "        os.mkdir (path)\n",
    "    else:\n",
    "        print('文件夹已经存在：%s' % path)\n",
    "        shutil.rmtree(path)\n",
    "        os.mkdir (path)\n",
    "\n",
    "# 限制训练文件数量,0不限制\n",
    "def copy_image_bytype(srcpath, destpath, limitcount = 0):\n",
    "    '''\n",
    "    将猫狗文件分别拷贝到不同文件夹下\n",
    "    '''\n",
    "    \n",
    "    filenames = [item.split(splitflag)[-1] for item in sorted(srcpath)]\n",
    "    \n",
    "    count = 0\n",
    "    for src,name in zip(srcpath,filenames):\n",
    "        dst = destpath + \"/\" + name\n",
    "        if (os.path.exists(dst) == False):\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        # 跳出循环\n",
    "        if (limitcount == count):\n",
    "            break\n",
    "            \n",
    "    return count\n",
    "\n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 创建文件夹\n",
    "create_dir(notmatch_path)\n",
    "create_dir(all_path)\n",
    "\n",
    "create_dir(train_path)\n",
    "create_dir(dog_path)\n",
    "\n",
    "\n",
    "create_dir(testnew_path)\n",
    "create_dir(test_path)\n",
    "\n",
    "\n",
    "cat_path = 'images/all/trainnew/cats'\n",
    "create_dir(cat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 total dog categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理狗\n",
    "dogs_all = glob(\"images/train/dog.*\")\n",
    "\n",
    "# 整理狗数据\n",
    "count = copy_image_bytype(dogs_all, dog_path, train_limitcount)\n",
    "\n",
    "print('There are %d total dog categories.' % count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 total cat categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理猫\n",
    "cats_all = glob(\"images/train/cat.*\")\n",
    "\n",
    "# 整理猫数据\n",
    "count = copy_image_bytype(cats_all, cat_path, train_limitcount)\n",
    "\n",
    "print('There are %d total cat categories.' % count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 total test categories.\n"
     ]
    }
   ],
   "source": [
    "# 处理测试数据\n",
    "test_all = glob(\"images/test/*\")\n",
    "\n",
    "# 整理猫数据\n",
    "count = copy_image_bytype(test_all, test_path, test_limitcount)\n",
    "\n",
    "print('There are %d total test categories.' % count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "#当前使用的样例\n",
    "dogs_list = glob(dog_path+'/dog.*')\n",
    "print(len(dogs_list))\n",
    "\n",
    "test_list = glob(test_path+'/*')\n",
    "print(len(test_list))\n",
    "\n",
    "cats_list = glob(cat_path+'/cat.*')\n",
    "print(len(cats_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_filesizes(paths):\n",
    "    '''\n",
    "    获取文件大小\n",
    "    '''\n",
    "    filesizes = []\n",
    "    for path in paths:\n",
    "        size = os.path.getsize(path)\n",
    "        filesizes.append(size)\n",
    "    return filesizes\n",
    "\n",
    "def get_filepixs(paths):\n",
    "    '''\n",
    "    获取像素：长和宽\n",
    "    '''\n",
    "    filepixs = []\n",
    "    xpixs = []\n",
    "    ypixs = []\n",
    "    for path in paths:\n",
    "        img = Image.open(path)\n",
    "        pix = img.size #图片的长和宽\n",
    "        xpixs.append(pix[0]) #图片的宽\n",
    "        ypixs.append(pix[1]) #图片的长\n",
    "        if (pix[0] > 1000):\n",
    "            print(path)\n",
    "    filepixs.append(xpixs)\n",
    "    filepixs.append(ypixs)    \n",
    "    \n",
    "    return filepixs\n",
    "    \n",
    "def draw_hist(mylist, title, xlabel, ylabel, xmin, xmax, ymin, ymax):\n",
    "    '''\n",
    "    绘制直方图，参数依次为list,抬头,X轴标签,Y轴标签,XY轴的范围\n",
    "    '''\n",
    "    plt.hist(mylist, 100)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def draw_scatter(x1, y1, title, label):\n",
    "    '''\n",
    "    绘制像素的散点图\n",
    "    '''\n",
    "    plt.scatter(x1, y1, marker = 'x',color = 'red', s = 40 ,label = label)\n",
    "    plt.xlabel('wide')\n",
    "    plt.ylabel('length')\n",
    "    plt.title(title)\n",
    "    \n",
    "#     plt.xlim(-1.5, 1.5)\n",
    "#     plt.xticks(())  # ignore xticks\n",
    "#     plt.ylim(-1.5, 1.5)\n",
    "#     plt.yticks(())  # ignore yticks\n",
    "\n",
    "    plt.show()   \n",
    "\n",
    "    \n",
    "def show_filesize(paths):\n",
    "    '''\n",
    "    展示文件大小分布\n",
    "    '''\n",
    "    filesizes = get_filesizes(paths)\n",
    "\n",
    "    # train 中文件的的最小值、最大值、中位数、众数\n",
    "    train_min = np.min(filesizes)\n",
    "    print('train 中文件的的最小值:', train_min)\n",
    "    train_max = np.max(filesizes)\n",
    "    print('train 中文件的的最大值:', train_max)\n",
    "    train_median = np.median(filesizes)\n",
    "    print('train 中文件的的中位数:', train_median)\n",
    "    train_mode = spmode(filesizes)\n",
    "    print('train 中文件的的众数:', train_mode)\n",
    "        \n",
    "    title = 'file size distribute'\n",
    "    xlabel = 'file size'\n",
    "    ylabel = 'file count'\n",
    "    xmin = np.min(filesizes)\n",
    "    xmax = np.max(filesizes)\n",
    "    ymin = 0\n",
    "    ymax = 1200\n",
    "    draw_hist(filesizes, title, xlabel, ylabel, xmin, xmax, ymin, ymax)\n",
    "\n",
    "# 训练数据集文件大小的分布\n",
    "# show_filesize(dogs_list)        \n",
    "# 测试数据集文件大小的分布\n",
    "# show_filesize(cats_list)          \n",
    "    \n",
    "def show_filepix(paths):\n",
    "    '''\n",
    "    显示像素分布\n",
    "    '''\n",
    "    filepixs = get_filepixs(paths)\n",
    "    title = 'file pix distribute'\n",
    "    draw_scatter(filepixs[0], filepixs[1], title, 'dog')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/all/trainnew/dogs/dog.9990.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 狗的数据集图片大小分布\n",
    "\n",
    "show_filepix(dogs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/all/trainnew/cats/cat.1689.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 猫的数据集图片大小分布\n",
    "show_filepix(cats_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 异常数据清理\n",
    "\n",
    "异常数据有:\n",
    "\n",
    "标签与图片信息不相符的，例如：虽然标识了是狗的图片，但是图片中没有狗。\n",
    "\n",
    "照片的背景过于复杂，识别起来很困难，例如：虽然有狗但是有很多干扰元素。\n",
    "\n",
    "这里选择4种算法:ResNet50, VGG19, Xception, InceptionV3 获取的并集进行数据清理\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "#可能概率前几个类型\n",
    "topparma = 50\n",
    "# 筛选的数量\n",
    "doglimit = train_limitcount\n",
    "catlimit = train_limitcount\n",
    "\n",
    "\n",
    "# 对 ImageNet 分类进行分析\n",
    "# 狗分类：118种，猫分类：7种\n",
    "\n",
    "ImageNetdogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "ImageNetcats=[\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_animalarray(model, top, animalarray,img_paths, xsize, ysize, preprocess_input, decode_predictions):\n",
    "    '''\n",
    "    清理数据集中不是对应标签的文件\n",
    "    model:模型\n",
    "    top:可能概率前几个类型\n",
    "    animalarray: ImageNet分类集\n",
    "    img_paths:数据集路径\n",
    "    x:图片宽\n",
    "    y:图片高\n",
    "    '''\n",
    "    animals = []\n",
    "    for img_path in img_paths:\n",
    "        img = image.load_img(img_path, target_size=(xsize, ysize))\n",
    "        imgarray = image.img_to_array(img)\n",
    "        imgarray = np.expand_dims(imgarray, axis=0)\n",
    "        imgarray = preprocess_input(imgarray)\n",
    "\n",
    "        preds = model.predict(imgarray)\n",
    "        predarray = decode_predictions(preds, top=top)\n",
    "#         sorted(tmparray, key=lambda tmp: tmp[2], reverse=True) \n",
    "\n",
    "        # 判断是否有指定类型存在\n",
    "        existflag = False\n",
    "        for n in range(top):\n",
    "            animal = predarray[0][n][0]\n",
    "            if animal in animalarray:\n",
    "                existflag = True\n",
    "                break\n",
    "        if existflag == False:\n",
    "            animals.append(img_path)\n",
    "            \n",
    "    return animals\n",
    "\n",
    "# [[('n02092002', 'Scottish_deerhound', 0.21568948),('n02097130', 'giant_schnauzer', 0.074100845)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用ResNet50网络进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "ResNet50_model = ResNet50(weights='imagenet')\n",
    "\n",
    "print(doglimit)\n",
    "print(catlimit)\n",
    "\n",
    "# # 不是狗的\n",
    "# ResNet50_notdogs = get_not_animalarray(ResNet50_model, topparma, ImageNetdogs, dogs_list[0:doglimit], 224, 224, preprocess_input, decode_predictions)\n",
    "# print(ResNet50_notdogs)\n",
    "\n",
    "# # 不是猫的\n",
    "# ResNet50_notcats = get_not_animalarray(ResNet50_model, topparma, ImageNetcats, cats_list[0:catlimit], 224, 224, preprocess_input, decode_predictions)\n",
    "# print(ResNet50_notdogs)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用VGG19网络进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input,decode_predictions\n",
    "\n",
    "VGG19_model = VGG19(weights='imagenet')\n",
    "\n",
    "# # 不是狗的\n",
    "# VGG19_notdogs = get_not_animalarray(VGG19_model, topparma, ImageNetdogs, dogs_list[0:doglimit], 224, 224, preprocess_input, decode_predictions)\n",
    "# print(VGG19_notdogs)\n",
    "\n",
    "# # 不是猫的\n",
    "# VGG19_notcats = get_not_animalarray(VGG19_model, topparma, ImageNetcats, cats_list[0:catlimit], 224, 224, preprocess_input, decode_predictions)\n",
    "# print(VGG19_notcats)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用Xception网络进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input,decode_predictions\n",
    "\n",
    "Xception_model = Xception(weights='imagenet')\n",
    "\n",
    "# # 不是狗的\n",
    "# Xception_notdogs = get_not_animalarray(Xception_model, topparma, ImageNetdogs, dogs_list[0:doglimit], 299, 299, preprocess_input, decode_predictions)\n",
    "# print(Xception_notdogs)\n",
    "\n",
    "# # 不是猫的\n",
    "# Xception_notcats = get_not_animalarray(Xception_model, topparma, ImageNetcats, cats_list[0:catlimit], 299, 299, preprocess_input, decode_predictions)\n",
    "# print(Xception_notcats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用InceptionV3网络进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input,decode_predictions\n",
    "\n",
    "InceptionV3_model = InceptionV3(weights='imagenet')\n",
    "\n",
    "# # 不是狗的\n",
    "# InceptionV3_notdogs = get_not_animalarray(InceptionV3_model, topparma, ImageNetdogs, dogs_list[0:doglimit], 299, 299, preprocess_input, decode_predictions)\n",
    "# print(InceptionV3_notdogs)\n",
    "\n",
    "# # 不是猫的\n",
    "# InceptionV3_notcats = get_not_animalarray(InceptionV3_model, topparma, ImageNetcats, cats_list[0:catlimit], 299, 299, preprocess_input, decode_predictions)\n",
    "# print(InceptionV3_notcats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并结果集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 合并所有的结果，取并集\n",
    "# notdogs = ResNet50_notdogs + VGG19_notdogs + Xception_notdogs + InceptionV3_notdogs\n",
    "# notdogs = list(set(notdogs))\n",
    "# print(notdogs)\n",
    "\n",
    "# notcats = ResNet50_notcats + VGG19_notcats + Xception_notcats + InceptionV3_notdogs\n",
    "# notcats = list(set(notcats))\n",
    "# print(notcats)\n",
    "\n",
    "\n",
    "# notmatchs = notdogs + notcats\n",
    "# print(len(notmatchs))\n",
    "# # notmatchs = notdogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存异常数据列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存异常数据列表\n",
    "# f = open('notmatchs.txt','w')\n",
    "# f.write(','.join(notmatchs))\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 剔除异常数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "def show_multiple_image(images):\n",
    "    '''\n",
    "    展示多组图片\n",
    "    '''\n",
    "    count = 1\n",
    "    row = len(images) / 4\n",
    "    col = 4\n",
    "    if (row < 1):\n",
    "        row = 1\n",
    "    for image in images:\n",
    "        plt.figure(num='astronaut', figsize =(12,15))  #创建一个名为astronaut的窗口,并设置大小 \n",
    "        img = plt.imread(image)  \n",
    "        if (count == 1):\n",
    "            plt.subplot(row,col,count)     #将窗口分为两行两列四个子图，则可显示四幅图片\n",
    "            plt.title(image.split(splitflag)[-1])   #第一幅图片标题l\n",
    "            plt.imshow(img)      #绘制第一幅图片\n",
    "        else:\n",
    "            plt.subplot(row,col,count)     #第三个子图\n",
    "            plt.title(image.split(splitflag)[-1])   #第一幅图片标题l\n",
    "            plt.imshow(img)      #绘制第一幅图片\n",
    "\n",
    "        if (count >= 8):\n",
    "            count += 1\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "    plt.show()   #显示窗口\n",
    "\n",
    "\n",
    "# test1=['images/all/testnew/test\\\\1.jpg', 'images/all/testnew/test\\\\10.jpg', 'images/all/testnew/test\\\\100.jpg', 'images/all/testnew/test\\\\1000.jpg']    \n",
    "# test2=['images/all/testnew/test\\\\1.jpg', 'images/all/testnew/test\\\\10.jpg', 'images/all/testnew/test\\\\100.jpg', 'images/all/testnew/test\\\\1000.jpg']    \n",
    "# test3=['images/all/testnew/test\\\\1.jpg', 'images/all/testnew/test\\\\10.jpg', 'images/all/testnew/test\\\\100.jpg', 'images/all/testnew/test\\\\1000.jpg']    \n",
    "# test4=['images/all/testnew/test\\\\101.jpg', 'images/all/testnew/test\\\\102.jpg', 'images/all/testnew/test\\\\100.jpg', 'images/all/testnew/test\\\\1000.jpg']    \n",
    "# test5=[]\n",
    "# test = test1+ test2 + test3 + test4\n",
    "# print(len(notmatchs))\n",
    "# show_multiple_image(notmatchs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file_as_str(file_path):\n",
    "    # 判断路径文件存在\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise TypeError(file_path + \" does not exist\")\n",
    "\n",
    "    all_the_text = open(file_path).read()\n",
    "    # print type(all_the_text)\n",
    "    return all_the_text\n",
    "\n",
    "\n",
    "def file_move(srcpath, despath):\n",
    "    filenames = [item.split(splitflag)[-1] for item in sorted(srcpath)]\n",
    "    count = len(filenames)\n",
    "        \n",
    "    for src,name in zip(srcpath,filenames):\n",
    "        dst = despath + \"/\" + name\n",
    "        if (os.path.exists(src) == True):\n",
    "            shutil.move(src, dst)\n",
    "            \n",
    "    return count\n",
    "        \n",
    "notmatch_str = read_file_as_str(notmatch_txt)\n",
    "notmatchs = []\n",
    "notmatchs = notmatch_str.strip(',').split(',')\n",
    "# print(notmatch_txt)\n",
    "# print(notmatchs[0])\n",
    "# print(notmatch_path)  \n",
    "    \n",
    "\n",
    "# 剔除异常数据\n",
    "file_move(notmatchs, notmatch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from keras.layers import GlobalAveragePooling2D,Dense\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import Adagrad\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/all/trainnew/dogs/dog.8144.jpg'\n",
      " 'images/all/trainnew/cats/cat.6017.jpg'\n",
      " 'images/all/trainnew/dogs/dog.7222.jpg' ...\n",
      " 'images/all/trainnew/cats/cat.7782.jpg'\n",
      " 'images/all/trainnew/cats/cat.8659.jpg'\n",
      " 'images/all/trainnew/cats/cat.1273.jpg']\n",
      "[1. 0. 1. ... 0. 0. 0.]\n",
      "训练集数据总数：24722\n",
      "19777\n",
      "4945\n",
      "[0. 0. 1. ... 0. 1. 0.]\n",
      "[1. 1. 1. ... 1. 0. 1.]\n",
      "测试集数据总数：12500\n"
     ]
    }
   ],
   "source": [
    "# 加载 train 测试数据集\n",
    "train_data = load_files(train_path)\n",
    "\n",
    "# 加载 test 测试数据集\n",
    "test_data = load_files(testnew_path)    \n",
    "\n",
    "trainall_file = np.array(train_data['filenames'])\n",
    "trainall_targets = np_utils.to_categorical(np.array(train_data['target']), 2)\n",
    "trainall_targets = np.array(trainall_targets)[:,1]\n",
    "# print(type(train_data))\n",
    "print(trainall_file)\n",
    "print(trainall_targets)\n",
    "\n",
    "# 展示训练数据集\n",
    "print('训练集数据总数：%d' % len(trainall_file))\n",
    "\n",
    "\n",
    "# 将原来的训练数据分割成训练数据集和验证数据集，比例为20%\n",
    "train_files, valid_files, mytrain_targets, myvalid_targets = train_test_split(trainall_file, trainall_targets, test_size=0.2)\n",
    "\n",
    "print(len(train_files))\n",
    "print(len(valid_files))\n",
    "print(mytrain_targets)\n",
    "print(myvalid_targets)\n",
    "\n",
    "\n",
    "test_files = np.array(test_data['filenames'])\n",
    "test_targets = np_utils.to_categorical(np.array(test_data['target']), 1)\n",
    "\n",
    "# 展示测试数据集\n",
    "print('测试集数据总数：%d' % len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile  \n",
    "from PIL import Image\n",
    "# sys.modules['Image'] = Image \n",
    "# from PIL import Image\n",
    "# print(Image.__file__)\n",
    "# import Image\n",
    "# print(Image.__file__)\n",
    "\n",
    "# ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# def path_to_tensor(img_path):\n",
    "# #     print(img_path)\n",
    "#     # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "#     img = image_utils.load_img(img_path,target_size=(299,299))\n",
    "    \n",
    "#     #将PIL.Image.Image类型转化为格式为(299,299,3)的3维张量\n",
    "#     x = image_utils.img_to_array(img)\n",
    "    \n",
    "#     #将3维张量转化为格式为(1, 299, 299, 3) 的4维张量并返回\n",
    "#     return np.expand_dims(x, axis=0)\n",
    "\n",
    "# def paths_to_tensor(img_paths):\n",
    "#     list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "#     return np.vstack(list_of_tensors)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    gen = ImageDataGenerator()\n",
    "    generator = gen.flow_from_directory(img_paths, (299,299), shuffle=False, \n",
    "                                              batch_size=16)\n",
    "    return generator\n",
    "\n",
    "# img_path='images/all/train/trainnew/cats/cat.4424.jpg'\n",
    "# paths_to_tensor(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `array_to_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-b9f777774353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'images/all/trainnew/cats/cat.1584.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# img = Image.open(img_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#将PIL.Image.Image类型转化为格式为(299,299,3)的3维张量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         raise ImportError('Could not import PIL.Image. '\n\u001b[0m\u001b[1;32m    494\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[1;32m    495\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import PIL.Image. The use of `array_to_img` requires PIL."
     ]
    }
   ],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# img_path='images/all/trainnew/cats/cat.1584.jpg'\n",
    "# img = load_img(img_path,target_size=(299,299))\n",
    "# # img = Image.open(img_path)\n",
    "# #将PIL.Image.Image类型转化为格式为(299,299,3)的3维张量\n",
    "# x = img_to_array(img)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-26 08:48:33\n",
      "Found 24722 images belonging to 2 classes.\n",
      "end time:2018-09-26 08:48:35\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 训练集预处理\n",
    "# mytrain_tensors = paths_to_tensor(train_files).astype('float32')/127.5 - 1\n",
    "# print(mytrain_tensors.shape)\n",
    "\n",
    "mytrain_tensors = paths_to_tensor(train_path)\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-26 11:53:06\n",
      "end time:2018-09-26 11:53:06\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 验证集预处理\n",
    "# myvalid_tensors = paths_to_tensor(valid_files).astype('float32')/127.5 - 1\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-26 08:49:34\n",
      "Found 12500 images belonging to 1 classes.\n",
      "end time:2018-09-26 08:49:36\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 测试集预处理\n",
    "# mytest_tensors = paths_to_tensor(test_files).astype('float32')/127.5 - 1\n",
    "mytest_tensors = paths_to_tensor(testnew_path)\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 导出特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-6ccff4ed7ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mwrite_gap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mwrite_gap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInceptionV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mwrite_gap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-6ccff4ed7ac1>\u001b[0m in \u001b[0;36mwrite_gap\u001b[0;34m(MODEL, image_size, lambda_func)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py\u001b[0m in \u001b[0;36midentity_block\u001b[0;34m(input_tensor, kernel_size, filters, stage, block)\u001b[0m\n\u001b[1;32m     61\u001b[0m     x = layers.Conv2D(filters1, (1, 1),\n\u001b[1;32m     62\u001b[0m                       \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                       name=conv_name_base + '2a')(input_tensor)\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbn_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbn_name_base\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'2a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    136\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             self.bias = self.add_weight(shape=(self.filters,),\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[1;32m    250\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m.87962566103423978\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             return K.truncated_normal(shape, 0., stddev,\n\u001b[0;32m--> 214\u001b[0;31m                                       dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(shape, mean, stddev, dtype, seed)\u001b[0m\n\u001b[1;32m   4093\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4094\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4095\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m         shape_tensor, dtype, seed=seed1, seed2=seed2)\n\u001b[1;32m    175\u001b[0m     \u001b[0mmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstddev_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 297\u001b[0;31m         \"Add\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 instructions)\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(extract_frame_info_fn)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mframe_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_frame_info_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     ret.append((filename, lineno, name, frame_globals, func_start_lineno,\n\u001b[0;32m---> 63\u001b[0;31m                 frame_info))\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 导出特征向量\n",
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(train_path, image_size, shuffle=False, \n",
    "                                              batch_size=16)\n",
    "    test_generator = gen.flow_from_directory(testnew_path, image_size, shuffle=False, \n",
    "                                             batch_size=16, class_mode=None)\n",
    "\n",
    "    nb_sample = len(train_generator.filenames)\n",
    "    print('nb_sample:',nb_sample)\n",
    "    train = model.predict_generator(train_generator, len(train_generator.filenames), verbose=1)\n",
    "    nb_sample = len(test_generator.filenames)\n",
    "    test = model.predict_generator(test_generator, len(test_generator.filenames), verbose=1)\n",
    "    with h5py.File(\"gap_%s.h5\"%MODEL.func_name) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "\n",
    "write_gap(ResNet50, (224, 224))\n",
    "write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
    "write_gap(Xception, (299, 299), xception.preprocess_input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2 构建模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 训练模型\n",
    "\n",
    "训练 InceptionV3 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 载入特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ..., 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#载入特征向量\n",
    "train_tensors = []\n",
    "test_tensors = []\n",
    "\n",
    "for filename in [\"saved_models/gap_ResNet50.h5\", \"saved_models/gap_Xception.h5\", \"saved_models/gap_InceptionV3.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        train_tensors.append(np.array(h['train']))\n",
    "        test_tensors.append(np.array(h['test']))\n",
    "        train_targets = np.array(h['label'])\n",
    "\n",
    "train_tensors = np.concatenate(train_tensors, axis=1)\n",
    "test_tensors = np.concatenate(test_tensors, axis=1)\n",
    "train_tensors, train_targets = shuffle(train_tensors, train_targets)\n",
    "\n",
    "# print(train_tensors)\n",
    "print(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 128\n",
    "patience=10\n",
    "\n",
    "# logloss 趋势图\n",
    "def show_logloss(history_callback):\n",
    "    plt.plot(history_callback.history['loss'])\n",
    "    plt.plot(history_callback.history['val_loss'])\n",
    "    plt.title(\"model loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\",\"test\"],loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 准确率趋势图\n",
    "def show_acc(history_callback):\n",
    "    plt.plot(history_callback.history['acc'])\n",
    "    plt.plot(history_callback.history['val_acc'])\n",
    "    plt.title(\"model acc\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\",\"test\"],loc=\"upper left\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 1.构建不带分类器的预训练模型\n",
    "base_model = InceptionV3(weights='imagenet',include_top=False) \n",
    "\n",
    "# 2.添加全局平均池化层\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 3.全连接层，可选，如果精度够用则可以不加\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# 4. 添加一个分类器，使用 1 个神经元，sigmoid激活函数\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# 5. 构建我们需要训练的完整模型\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# 6.首先只训练顶部的几层（随机初始化的层），锁住所有 InceptionV3d 卷积层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 7.编译模型（一定要在锁层以后操作）\n",
    "# model.compile(optimizer='adadelta', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('compile ok')\n",
    "\n",
    "\n",
    "# 8. 在新的数据集上训练几代\n",
    "# early stoppping \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# monitor: 需要监视的变量\n",
    "# patience:在发现变量没有变化后的多少个epoch停止\n",
    "# verbose:信息展示模式\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "callback_lists = [tensorboard, early_stopping]\n",
    "\n",
    "history_callback_1 = model.fit(mytrain_tensors, mytrain_targets, batch_size=batch_size, \n",
    "                               epochs=epochs, validation_split=0.2, verbose=1, callbacks=callback_lists)\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile ok\n",
      "start time:2018-09-25 16:09:48\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0516 - acc: 0.9800 - val_loss: 0.0195 - val_acc: 0.9934\n",
      "Epoch 2/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0210 - acc: 0.9934 - val_loss: 0.0172 - val_acc: 0.9944\n",
      "Epoch 3/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0160 - acc: 0.9943 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "Epoch 4/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0154 - acc: 0.9953 - val_loss: 0.0179 - val_acc: 0.9934\n",
      "Epoch 5/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0166 - val_acc: 0.9942\n",
      "Epoch 6/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0114 - acc: 0.9959 - val_loss: 0.0168 - val_acc: 0.9942\n",
      "Epoch 7/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0101 - acc: 0.9971 - val_loss: 0.0164 - val_acc: 0.9946\n",
      "Epoch 8/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0093 - acc: 0.9968 - val_loss: 0.0164 - val_acc: 0.9950\n",
      "Epoch 9/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0161 - val_acc: 0.9950\n",
      "Epoch 10/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0073 - acc: 0.9973 - val_loss: 0.0171 - val_acc: 0.9948\n",
      "Epoch 11/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0086 - acc: 0.9968 - val_loss: 0.0181 - val_acc: 0.9948\n",
      "Epoch 12/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0072 - acc: 0.9979 - val_loss: 0.0187 - val_acc: 0.9938\n",
      "Epoch 13/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0168 - val_acc: 0.9944\n",
      "Epoch 14/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "Epoch 15/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0179 - val_acc: 0.9942\n",
      "Epoch 16/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0058 - acc: 0.9978 - val_loss: 0.0188 - val_acc: 0.9946\n",
      "Epoch 17/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0051 - acc: 0.9980 - val_loss: 0.0209 - val_acc: 0.9944\n",
      "Epoch 18/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0050 - acc: 0.9981 - val_loss: 0.0191 - val_acc: 0.9940\n",
      "Epoch 19/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0184 - val_acc: 0.9942\n",
      "Epoch 20/300\n",
      "20000/20000 [==============================] - 1s - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0190 - val_acc: 0.9946\n",
      "Epoch 00019: early stopping\n",
      "end time:2018-09-25 16:10:25\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(train_tensors.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=input_tensor, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('compile ok')\n",
    "\n",
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 8. 在新的数据集上训练几代\n",
    "# early stoppping \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# monitor: 需要监视的变量\n",
    "# patience:在发现变量没有变化后的多少个epoch停止\n",
    "# verbose:信息展示模式\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "callback_lists = [tensorboard, early_stopping]\n",
    "\n",
    "history_callback_1 = model.fit(train_tensors, train_targets, batch_size=batch_size, \n",
    "                               epochs=epochs, validation_split=0.2, verbose=1, callbacks=callback_lists)\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_6:0\", shape=(?, 6144), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6145      \n",
      "=================================================================\n",
      "Total params: 6,145.0\n",
      "Trainable params: 6,145.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLEREpEsKCxER6dL/D5qbB39tE9bkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31d9ac6908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 展示logloss趋势\n",
    "show_logloss(history_callback_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_6 False\n",
      "1 dropout_1 True\n",
      "2 dense_2 True\n"
     ]
    }
   ],
   "source": [
    "# 9.现在顶层应该训练好了，开始微调 InceptionV3的卷积层。\n",
    "#锁住底下的几层，然后训练其余的顶层。查看每一层的名字和层号，看看应该锁多少层\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name,layer.trainable)\n",
    "    \n",
    "# conv2d_841 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: input_6 True\n",
      "before: dropout_1 True\n",
      "before: dense_2 True\n"
     ]
    }
   ],
   "source": [
    "# 10.我们选择训练最上面的两个 Inception block, 锁住前面249层，然后放开之后的层\n",
    "# for layer in model.layers[:249]:\n",
    "#     print('before:',layer.name,layer.trainable)\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[249:]:\n",
    "#     print('after:',layer.name,layer.trainable)\n",
    "#     layer.trainable = True    \n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = True\n",
    "    print('before:',layer.name,layer.trainable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile ok\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# 11.重新编译模型，使上面的修改生效，设置一个很低的学习率:lr=0.001，使用SGD来微调\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0., decay=0., nesterov=False), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('compile ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:2018-09-25 16:12:08\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9985Epoch 00000: val_loss improved from inf to 0.01895, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 2s - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0189 - val_acc: 0.9946\n",
      "Epoch 2/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9985Epoch 00001: val_loss improved from 0.01895 to 0.01893, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0189 - val_acc: 0.9946\n",
      "Epoch 3/300\n",
      "19584/20000 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9983Epoch 00002: val_loss improved from 0.01893 to 0.01891, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0189 - val_acc: 0.9946\n",
      "Epoch 4/300\n",
      "19584/20000 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9988Epoch 00003: val_loss improved from 0.01891 to 0.01890, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0189 - val_acc: 0.9946\n",
      "Epoch 5/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9986Epoch 00004: val_loss improved from 0.01890 to 0.01888, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0189 - val_acc: 0.9946\n",
      "Epoch 6/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9988Epoch 00005: val_loss improved from 0.01888 to 0.01886, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0189 - val_acc: 0.9946\n",
      "Epoch 7/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987Epoch 00006: val_loss improved from 0.01886 to 0.01885, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0189 - val_acc: 0.9946\n",
      "Epoch 8/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9987Epoch 00007: val_loss improved from 0.01885 to 0.01884, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0188 - val_acc: 0.9946\n",
      "Epoch 9/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9986Epoch 00008: val_loss improved from 0.01884 to 0.01883, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0188 - val_acc: 0.9946\n",
      "Epoch 10/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9990Epoch 00009: val_loss improved from 0.01883 to 0.01882, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0188 - val_acc: 0.9946\n",
      "Epoch 11/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0040 - acc: 0.9987Epoch 00010: val_loss improved from 0.01882 to 0.01881, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0188 - val_acc: 0.9946\n",
      "Epoch 12/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0051 - acc: 0.9982Epoch 00011: val_loss improved from 0.01881 to 0.01880, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "Epoch 13/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0037 - acc: 0.9989Epoch 00012: val_loss improved from 0.01880 to 0.01879, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "Epoch 14/300\n",
      "19712/20000 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9988Epoch 00013: val_loss improved from 0.01879 to 0.01878, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "Epoch 15/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0048 - acc: 0.9984Epoch 00014: val_loss improved from 0.01878 to 0.01877, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "Epoch 16/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 0.9987Epoch 00015: val_loss improved from 0.01877 to 0.01876, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "Epoch 17/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9986Epoch 00016: val_loss improved from 0.01876 to 0.01875, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "Epoch 18/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988Epoch 00017: val_loss improved from 0.01875 to 0.01875, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 19/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988Epoch 00018: val_loss improved from 0.01875 to 0.01874, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 20/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9987Epoch 00019: val_loss improved from 0.01874 to 0.01873, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 21/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987Epoch 00020: val_loss improved from 0.01873 to 0.01873, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 22/300\n",
      "19584/20000 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9988Epoch 00021: val_loss improved from 0.01873 to 0.01873, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 23/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9988Epoch 00022: val_loss improved from 0.01873 to 0.01872, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 24/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0041 - acc: 0.9990Epoch 00023: val_loss improved from 0.01872 to 0.01871, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 25/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9982Epoch 00024: val_loss improved from 0.01871 to 0.01871, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 26/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19712/20000 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9987Epoch 00025: val_loss improved from 0.01871 to 0.01870, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 27/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9988Epoch 00026: val_loss improved from 0.01870 to 0.01870, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 28/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9987Epoch 00027: val_loss improved from 0.01870 to 0.01870, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 29/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9988Epoch 00028: val_loss improved from 0.01870 to 0.01869, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 30/300\n",
      "19584/20000 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9985Epoch 00029: val_loss improved from 0.01869 to 0.01869, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 31/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9987Epoch 00030: val_loss improved from 0.01869 to 0.01869, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 32/300\n",
      "19712/20000 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9986Epoch 00031: val_loss improved from 0.01869 to 0.01869, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 33/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 0.9988Epoch 00032: val_loss improved from 0.01869 to 0.01868, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 34/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9988Epoch 00033: val_loss improved from 0.01868 to 0.01868, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 35/300\n",
      "19712/20000 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9989Epoch 00034: val_loss improved from 0.01868 to 0.01868, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 36/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0036 - acc: 0.9991Epoch 00035: val_loss improved from 0.01868 to 0.01868, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 37/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9990Epoch 00036: val_loss improved from 0.01868 to 0.01868, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 38/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9981Epoch 00037: val_loss improved from 0.01868 to 0.01868, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0049 - acc: 0.9981 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 39/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0043 - acc: 0.9986Epoch 00038: val_loss improved from 0.01868 to 0.01867, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 40/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9983Epoch 00039: val_loss improved from 0.01867 to 0.01867, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 41/300\n",
      "19712/20000 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9985Epoch 00040: val_loss improved from 0.01867 to 0.01867, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 42/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0039 - acc: 0.9988Epoch 00041: val_loss improved from 0.01867 to 0.01867, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 43/300\n",
      "19712/20000 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9984Epoch 00042: val_loss improved from 0.01867 to 0.01867, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 44/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9985Epoch 00043: val_loss improved from 0.01867 to 0.01867, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 45/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9983Epoch 00044: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 46/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9986Epoch 00045: val_loss improved from 0.01867 to 0.01866, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 47/300\n",
      "19584/20000 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988Epoch 00046: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 48/300\n",
      "19200/20000 [===========================>..] - ETA: 0s - loss: 0.0048 - acc: 0.9986Epoch 00047: val_loss improved from 0.01866 to 0.01866, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 49/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9991Epoch 00048: val_loss improved from 0.01866 to 0.01866, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 50/300\n",
      "19584/20000 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9988Epoch 00049: val_loss improved from 0.01866 to 0.01866, saving model to saved_models/weights.best.Inception.hdf5\n",
      "20000/20000 [==============================] - 1s - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 51/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9988Epoch 00050: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 52/300\n",
      "19328/20000 [===========================>..] - ETA: 0s - loss: 0.0046 - acc: 0.9981Epoch 00051: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0045 - acc: 0.9982 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 53/300\n",
      "19840/20000 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9991Epoch 00052: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 54/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9984Epoch 00053: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 55/300\n",
      "19456/20000 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9991Epoch 00054: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 56/300\n",
      "19200/20000 [===========================>..] - ETA: 0s - loss: 0.0043 - acc: 0.9986Epoch 00055: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 57/300\n",
      "19584/20000 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9984Epoch 00056: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0044 - acc: 0.9983 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 58/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9987Epoch 00057: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 59/300\n",
      "19584/20000 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9987Epoch 00058: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 60/300\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9988Epoch 00059: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 61/300\n",
      "19712/20000 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9985Epoch 00060: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 00060: early stopping\n",
      "end time:2018-09-25 16:13:49\n"
     ]
    }
   ],
   "source": [
    "starttime = time.strftime('start time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (starttime)\n",
    "\n",
    "# 12.继续训练模型，训练最后两个 Inception block 和两个全连接层\n",
    "Inceptionfile_hdf5 ='saved_models/weights.best.Inception.hdf5'\n",
    "\n",
    "# 模型保存\n",
    "checkpointer = ModelCheckpoint(filepath=Inceptionfile_hdf5, verbose=1, save_best_only=True)\n",
    "\n",
    "# 可视化\n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "\n",
    "# 自动停止训练\n",
    "# monitor: 需要监视的变量\n",
    "# patience:在发现变量没有变化后的多少个epoch停止\n",
    "# verbose:信息展示模式\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n",
    "\n",
    "\n",
    "callback_lists = [tensorboard, checkpointer, early_stopping]\n",
    "\n",
    "# # 训练模型\n",
    "# history_callback_2 = model.fit(train_tensors, train_targets, validation_split=0.2,\n",
    "#          epochs=epochs, batch_size=batch_size,callbacks=callback_lists,shuffle='True',verbose=1)\n",
    "\n",
    "history_callback_2 = model.fit(train_tensors, train_targets, batch_size=batch_size, \n",
    "                               epochs=epochs, validation_split=0.2, shuffle='True', verbose=1, callbacks=callback_lists)\n",
    "\n",
    "\n",
    "endtime = time.strftime('end time:%Y-%m-%d %H:%M:%S', time.localtime()) \n",
    "print (endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neMUCiTHGGK/8Pz/yoFlyPBvkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31c4551278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 展示logloss趋势\n",
    "show_logloss(history_callback_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 测试模型\n",
    "\n",
    "在测试数据集上试用训练后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11936/12500 [===========================>..] - ETA: 0sFound 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.763204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     label\n",
       "0   1  0.995000\n",
       "1   2  0.995000\n",
       "2   3  0.005000\n",
       "3   4  0.995000\n",
       "4   5  0.005000\n",
       "5   6  0.005000\n",
       "6   7  0.995000\n",
       "7   8  0.995000\n",
       "8   9  0.005000\n",
       "9  10  0.763204"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    " \n",
    "\n",
    "## 加载具有最好验证loss的模型\n",
    "# model.load_weights(Inceptionfile_hdf5)\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_tensors, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "# \n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(testnew_path, (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(10)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import *\n",
    "# import numpy as np\n",
    "# import random\n",
    "# import os\n",
    "# import cv2\n",
    "\n",
    "# def get_image(index):\n",
    "#     img = cv2.imread(testnew_path+'/test/%d.jpg' % index)\n",
    "#     img = cv2.resize(img,(299,299))\n",
    "#     img.astype(np.float32)\n",
    "#     img = img / 255.0\n",
    "#     return img\n",
    "\n",
    "# test_num = 12500\n",
    "\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# for i in range(20):\n",
    "#     x = get_image(random.randint(1, test_num))\n",
    "#     prediction = model.predict(np.expand_dims(x[0][0], axis=1))[0]\n",
    "    \n",
    "#     plt.subplot(4, 5, i+1)\n",
    "#     if prediction < 0.5:\n",
    "#         plt.title('cat %.2f%%' % (100 - prediction*100))\n",
    "#     else:\n",
    "#         plt.title('dog %.2f%%' % (prediction*100))\n",
    "    \n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(x[:,:,::-1]) # convert BGR to RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 提交 kaggle测试得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
